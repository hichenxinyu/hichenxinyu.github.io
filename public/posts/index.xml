<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on LeaveIt</title><link>https://example.com/posts/</link><description>Recent content in Posts on LeaveIt</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 23 Mar 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://example.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>我常用的 Mac 软件</title><link>https://example.com/2020/mac%E8%BD%AF%E4%BB%B6/</link><pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate><guid>https://example.com/2020/mac%E8%BD%AF%E4%BB%B6/</guid><description>选择软件的一些标准
跨平台 开源免费 简洁 无广告 Markdown编辑器：Typora+PicGo ​ 开源免费的，所见即所得的实时预览很舒服，界面也非常清爽，而且还是最近也支持了PicGo，配合腾讯云的COS来做图床，
编辑器 ：VScode ​ 日常写脚本，写个Python代码，丰富的插件，
视频播放器： IINA
解压缩软件：The Unarachiver
云盘： OneDrive ，iCloud OneDrive是Office 365 订阅赠送，日常来用作资料同步 ，Apple 全家桶的前提下，iCloud非常好用，免费的5GB也够用了，大文件放在Onedrive中。
Git GUI客户端：GitKraken ​ 非常经典的章鱼，感觉比Sourcetree好用，基于electron ，跨平台。免费版本也够用了，只是不支持github私有仓库。
终端：iTerm2 ​ iTerm2 +oh-my-zsh ，作为运维，命令行是经常打交道的地方，一个好看好用功能强大的终端是以一个很好的工具，Mac上最好用的终端工具
快捷工具：AIfred3 ​ 日常搜索文件，搜索软件速度更快</description></item><item><title>Kubernetes集群安装</title><link>https://example.com/2019/kubernetes-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/</link><pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/kubernetes-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/</guid><description>Master包含组件 Master 组件提供的集群控制，Master 组件对集群做出全局性决策(例如：调度)等，负责维护集群的目标状态。
组件 说明 etcd 用于 Kubernetes 的后端数据存储，所有集群数据都存储在此处 kube-apiserver 对外暴露了 Kubernetes API，它是的 Kubernetes 前端控制层，只有 API Server 会与 etcd 通信，其它模块都必须通过 API Server 访问集群状态。 kube-controller-manager 处理集群中常规任务，它是单独的进程，内部包含多个控制器，包含节点控制器,副本控制器,端点控制器,服务帐户和令牌控制器 kube-scheduler 监视新创建的 Pod 为新创建的 POD 分配合适的 node 节点 addons（插件） 插件是实现集群功能的 Pod 和 Service，一般被创建于 kube-system 命名空间。例如：coreDNS Node 包含组件 Node 节点实际负责实施，也就是运行 POD 的节点，上面运行的组件有
组件 说明 kubelet 它监测已经分配给自己的 Pod，为 POD 准备卷，下载 POD 所需的 Secret，下载镜像并运行，进行生命周期探测，上报 POD 和节点状态 kube-proxy 通过维护主机上的网络规则并执行连接转发，将 Kubernetes 提供的网络服务代理到每个节点上，实现了Kubernetes服务抽象 docker 用于运行容器 #!</description></item><item><title>Kafka &amp; ZooKeeper 集群搭建</title><link>https://example.com/2019/kafka-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</link><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/kafka-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</guid><description>环境准备 三台机器 CentOS 7.4 10.0.19.218 10.0.19.216 10.0.19.142
kafka 集群搭建准备:
Java环境 ZooKeeper 集群搭建 Zookeeper 集群搭建 server.1=10.0.19.218:2888:3888 server.2=10.0.19.216:2888:3888 server.3=10.0.19.142:2888:3888 echo &amp;quot;1&amp;quot; &amp;gt;/tmp/zookeeper/myid ##生成ID，这里需要注意， myid对应的zoo.cfg的server.ID，比如第二台zookeeper主机对应的myid应该是2 启动ZooKeeper
cd /usr/local/zookeeper-3.4.9/bin ./zkServer.sh start 停止Zookeeper
cd /usr/local/zookeeper-3.4.9/bin ./zkServer.sh stop 附美味测试环境Zookeeper 集群配置
[root@rdpops_server-146-199 conf]# cat zoo.cfg # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored.</description></item><item><title>Redis 持久化</title><link>https://example.com/2019/redis-%E6%8C%81%E4%B9%85%E5%8C%96/</link><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/redis-%E6%8C%81%E4%B9%85%E5%8C%96/</guid><description>Redis的读写性能俱佳，但由于是内存数据库，如果没有提前备份，Redis数据是掉电即失的。 Redis提供了两种方式进行持久化：
RDB持久化 AOF持久化 原理 将Redis在内存中的数据定时dump到磁盘上，实际操作过程是fork一个子进程，先将数据写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储 打印rdb文件
root@pa6:/var/lib/redis# od -c dump.rdb 0000000 R E D I S 0 0 0 6 376 \0 \0 003 k e y 0000020 301 177 # 377 ] } 362 366 313 362 n 020 0000034 AOF 持久化存储 AOF持久化：将Redis的操作日志以文件追加的方式写入文件，只记录写、删除操作，查询操作不会记录（类似于MySQL的Binlog日志）
因为BGSAVE命令可以在不阻塞服务器进程的情况下执行，所以Redis允许用户通过设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令 用户可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行BGSAVE命令 举个例子，如果我们向服务器提供以下配置 vim redis.conf
save 900 1 save 300 10 save 60 10000 那么只要满足以下三个条件中的任意一个，BGSAVE命令就会被执行 服务器在900秒之内，对数据库进行了至少1次修改 服务器在300秒之内，对数据库进行了至少10次修改 服务器在60秒之内，对数据库进行了至少10000次修改。
备份脚本 #!/bin/bash # 避免造成雪崩 set -e # bak 目录 BACKUPDIR=/data/redis/backup #PASSWD='redis密码' #DATADIR=`/usr/local/bin/redis-cli -p 端口 -a &amp;quot;$PASSWD&amp;quot; config get dir|grep -Ev 'dir|grep'` # 获取redis-cli 二进制文件 REDIS_CMD=$(which redis-cli) DATADIR=`$REDIS_CMD config get dir|grep -Ev 'dir|grep'` DATE=`date +'%Y-%m-%d-%H-%M'` BACKUPDIR_DATE=$BACKUPDIR_$DATE if [ !</description></item><item><title>Prometheus+Grafana监控实践</title><link>https://example.com/2019/prometheus/</link><pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/prometheus/</guid><description>什么是Prometheus Prometheus 是由 SoundCloud 开源监控告警解决方案，从 2012 年开始编写代码，再到 2015 年 github 上开源以来，已经吸引了 9k+ 关注，以及很多大公司的使用；2016 年 Prometheus 成为继 k8s 后，第二名 CNCF(Cloud Native Computing Foundation) 成员。
作为新一代开源解决方案，很多理念与 Google SRE 运维之道不谋而合。
为什么选择prometheus： Prometheus 是按照 Google SRE 运维之道的理念构建的，具有实用性和前瞻性。 Prometheus 社区非常活跃，基本稳定在 1个月1个版本的迭代速度，从 2016 年 v1.01 开始接触使用以来，到目前发布的 v1.8.2 以及最新最新的 v2.1 ，你会发现 Prometheus 一直在进步、在优化。 Go 语言开发，性能不错，安装部署简单，多平台部署兼容性好。 丰富的数据收集客户端，官方提供了各种常用 exporter。 丰富强大的查询能力,内置更强大的统计函数。 Prometheus 属于一站式监控告警平台，依赖少，功能齐全。 Prometheus支持对云或容器的监控，其他监控系统主要对主机监控。 Prometheus 在数据存储扩展性以及持久性上没有 InfluxDB，OpenTSDB，Sensu 好。
安装prometheus 下载二进制包 在这个页面https://prometheus.io/download 找到最新的二进制包 wget https://github.com/prometheus/prometheus/releases/download/v2.7.2/prometheus-2.7.2.linux-amd64.tar.gz 解压并进入对应文件夹 tar xvfz prometheus-*.</description></item><item><title>Gitlab CI/CD</title><link>https://example.com/2019/gitlab-ci/</link><pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/gitlab-ci/</guid><description>GitLab CI/CD 是gitlab8.0之后自带的一个持续集成系统，中心思想是当每一次push到gitlab的时候，都会触发一次脚本执行，然后脚本的内容包括了测试，编译，部署等一系列自定义的内容。
GitLab CI/CD的脚本执行，需要自定义安装对应gitlab-runner来执行，代码push之后，webhook检测到代码变化，就会触发gitlab-CI，分配到各个Runner来运行相应的脚本script。这些脚本有的是测试项目用的，有的是部署用的。
GitLab CI/CD 优势 轻量级，不需要复杂的安装手段。 配置简单，与gitlab可直接适配。 实时构建日志十分清晰，UI交互体验很好 使用 YAML 进行配置，任何人都可以很方便的使用。 GitLab CI/CD 劣势 没有统一的管理界面，无法统筹管理所有项目 配置依赖于代码仓库，耦合度没有Jenkins低 gitlab-runner 安装(个人比较喜欢 yum or rpm 安装软件)
#添加官方 yum 源 curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash #安装 gitlab-runner yum install gitlab-runner -y gitlab-runner 注册 gitlab-ci-multi-runner register #然后依次填入 gitlab url，Token，Runner 类型</description></item><item><title>ELK Stack 升级</title><link>https://example.com/2019/elk-stack-%E5%8D%87%E7%BA%A7%E7%AC%94%E8%AE%B0/</link><pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/elk-stack-%E5%8D%87%E7%BA%A7%E7%AC%94%E8%AE%B0/</guid><description>升级方案 比较常见的 ELK Stack 升级方式有一下 3 种
数据迁移升级：新建一套高版本 ES 集群，然后把老的 ES数据导入  滚动升级，5.0.0-&amp;gt;5.6,5.6-&amp;gt;6.8.2 集群重启升级，5.0.0-&amp;gt;6.8.2 升级方式 优点 缺点 数据迁移&amp;amp;升级 可以跨大版本升级 升级过程中，旧集群写操作停止 ES 版本之间有差异比较大，可能会有一些坑 迁移时间较长 滚动升级 升级过程中服务不中断 对ELK 源版本与目标版本有要求 集群重启升级 可以跨大版本升级 迁移时间比较短 ES 服务中断 公司生产环境与测试环境的 ELK 技术栈版本是 5.</description></item><item><title>ELK 问题排查</title><link>https://example.com/2019/elk%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</link><pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/elk%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</guid><description>集群 Red 为了完整的查看索引，分片，主分片和副分片情况，所以可直接使用自带 Api 查看，输入地址:
GET /_cat/shards?h=index,shard,prirep,state,unassigned.reason  查询索引有问题的原因
GET /_cluster/allocation/explain 官网文档 https://www.elastic.co/guide/en/elasticsearch/reference/master/cluster-allocation-explain.html
可以查看结果，线上 ES 是12个分片，3个备份，但是每个备份都会出现一个 UNASSIGNED 的情况，我们从最后的原因 INDEX CREATED 可得知是由于创建索引的API导致未分配。
trackmodel-2019-01-02 8 r UNASSIGNED INDEX CREATED trackmodel-2019-01-02 8 r STARTED trackmodel-2019-01-02 8 r STARTED trackmodel-2019-01-02 8 p STARTED trackmodel-2019-01-02 4 r STARTED trackmodel-2019-01-02 4 p STARTED trackmodel-2019-01-02 4 r STARTED trackmodel-2019-01-02 4 r UNASSIGNED INDEX CREATED trackmodel-2019-01-02 7 r STARTED trackmodel-2019-01-02 7 p STARTED trackmodel-2019-01-02 7 r STARTED trackmodel-2019-01-02 7 r UNASSIGNED INDEX CREATED .</description></item><item><title>ElasticSearch 压测</title><link>https://example.com/2019/elk%E5%8E%8B%E6%B5%8B/</link><pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/elk%E5%8E%8B%E6%B5%8B/</guid><description>本次压测目标： 测试集群读写性能 &amp;amp; 为集群容量规划提供数据支撑 测试 ES 新版本，结合实际场景与老版本进行比较，评估是否进行升级 性能优化&amp;amp;性能问题诊断 对 ES 配置参数进行修改，评估优化效果（长期） 确定系统稳定性，考察系统功能极限与稳定性 可选择的压测工具 Elastic 官方压测工具：rally 基于HTTP 的压测第三方压测工具：JMeter 等 压测流程如下 压测计划 脚本开发 压测环境搭建&amp;amp;压测开始 结果分析 为方便对比，压测数据统一使用 geonames 数据集（大小3.2G，共11523468个文档） 时间： 完整的一次压测过程，时间以小时计 安装 依赖
3.5+ including pip3  git 1.9+ JDK  pip3 install esrally Elastic 官方压测结果链接 https://elasticsearch-benchmarks.elastic.co/ 配置 esrally configure --advanced-config 只测试 1000 条数据
esrally --distribution-version=5.6.16 --test-mode 开始测试各版本单机性能
esrally race --distribution-version=5.</description></item><item><title>VScode使用笔记</title><link>https://example.com/2019/vscode%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate><guid>https://example.com/2019/vscode%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</guid><description>电脑可能会换，系统可能会换，但是编辑器，可能会跟你很久.
推荐安装插件: Atom One Dark Theme #Atom主题 Settings Sync #配置同步 VSCode Great Icons #文件图标替换 VScode写Python 比如要自动格式化代码，只需要按下Alt+Shift+F，vscode就会调用autopep8自动格式化代码 然后就开始自动安装autopep8. autopep8在每个python环境中都要安装 如果是是用python-autopep8的插件 则要在终端中使用brew install autopep8
python虚拟环境:virtualenv</description></item><item><title>Nginx实战</title><link>https://example.com/2018/nginx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate><guid>https://example.com/2018/nginx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid><description>搭建一个简易的代理服务 nginx 常常用来作为代理服务器，这代表着服务器接收请求，然后将它们传递给被代理服务器，得到请求的响应，再将它们发送给客户端。 我们将配置一个基本的代理服务器，它会处理本地图片文件的请求并返回其他的请求给被代理的服务器。在这个例子中，两个服务器都会定义在一个 nginx 实例中。 首先，通过在 nginx 配置文件中添加另一个 server 区块，来定义一个被代理的服务器，像下面的配置：
server { listen 8080; root /data/up1; location / { } } 上面就是一个简单的服务器，它监听在 8080 端口（之前，listen 并没被定义，是因为默认监听的 80 端口）并且会映射所有的请求给 本地文件目录 /data/up1。创建该目录，然后添加 index.html 文件。注意，root 指令是放在 server 上下文中。当响应请求的 location 区块中，没有自己的 root 指令，上述的 root 指令才会被使用。 接着，使用前面章节中的 server 配置，然后将它改为一个代理服务配置。在第一个 location 区块中，放置已经添加被代理服务器的协议，名字和端口等参数的 proxy_pass 指令（在这里，就是 http://localhost:8080）:
server { location / { proxy_pass http://localhost:8080; } location /images/ { root /data; } } location相关 我们将修改第二个 location 区块，使他返回一些典型后缀的图片文件请求， 现在它只会映射带有 /images/ 前缀的请求到 /data/images 目录下。 修改后的 location 指令如下：</description></item><item><title>Centos更换yum源</title><link>https://example.com/2018/%E6%9B%B4%E6%8D%A2yum%E6%BA%90/</link><pubDate>Fri, 02 Feb 2018 11:12:48 +0000</pubDate><guid>https://example.com/2018/%E6%9B%B4%E6%8D%A2yum%E6%BA%90/</guid><description>第一步：备份你的原镜像文件，以免出错后可以恢复。 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 第二步：下载新的CentOS-Base.repo 到/etc/yum.repos.d/ CentOS 6 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo CentOS 7 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 第三步：运行yum makecache生成缓存 yum clean all yum makecache</description></item><item><title>Zabbix4.4安装</title><link>https://example.com/2017/zabbix4.4-%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3/</link><pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate><guid>https://example.com/2017/zabbix4.4-%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3/</guid><description>Zabbix介绍 Zabbix 是一个企业级的分布式开源监控方案。 zabbix server ，zabbix agent&amp;gt; 与可选组件zabbix proxy。
API 功能 ： 应用api功能，可以方便的和其他系统结合，包括手机客户端的使用。
更多功能请查看http://www.zabbix.com/documentation.php
安装zabbix环境及准备工作 zabbix 依赖 LAMP （LNMP 也可以）
安装zabbix （单机）&amp;ndash;&amp;gt; LAMP （架构）&amp;ndash;&amp;gt; LAP + MYSQL（生产环境，建议数据库与 Zabbix-Server 分开部署） 服务端端口：10051 客户端端口：10050 1，安装Zabbix需要的硬件环境及软件版本，我这里在官网上查了一下，你可以根据自己的环境和要求来选择：下表是几个硬件配置的示例:
名称 平台 **CPU/**内存 数据库 监控主机数量 小型 CentOS 虚拟应用 MySQL InnoDB 100 中型 CentOS 2 CPU cores/2GB MySQL InnoDB 500 大型 RedHat Enterprise Linux 4 CPU cores/8GB RAID10 MySQL InnoDB or PostgreSQL &amp;gt;1000 巨大型 RedHat Enterprise Linux 8 CPU cores/16GB 快速RAID10 MySQL InnoDB or PostgreSQL &amp;gt;10000 具体的配置极其依赖于Active Item数量和轮询频率。如需要进行大规模部署，强烈建议将数据库进行独立部署。</description></item><item><title>Gerrit CodeReview代码审核工具搭建配置</title><link>https://example.com/1/gerrit-codereview%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/1/gerrit-codereview%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE/</guid><description>一、环境准备 OS:centos6.8 gerrit依赖 (java&amp;amp;git) yum -y install java-1.8.0 安装git 2.14.1 (低版本git同步gitlab时会出问题) yum install -y http://opensource.wandisco.com/centos/6/git/x86_64/wandisco-git-release-6-1.noarch.rpm yum install -y git yum -y install epel-release &amp;amp;&amp;amp; yum -y install nginx httpd-tools
gerrit环境 下载：Gerrit 2.15.1 wget https://www.gerritcodereview.com/download/gerrit-2.15.1.war
gerrit管理帐号(可选，使用独立账号配置gerrit) gerrit依赖，用来管理gerrit。 sudo adduser gerrit sudo passwd gerrit 并将gerrit加入sudo权限 sudo vi /etc/sudoers gerrit ALL=(ALL:ALL) ALL 备注：这里我直接使用root用户安装 二. 安装与配置gerrit 配置gerrit 默认安装：java -jar gerrit-2.15.1.war init -d /usr/local/review(此目录最好放在空间比较大的目录) 配置的时候 该选择Y的时候要选择Y</description></item><item><title>Yum 命令被锁</title><link>https://example.com/1/yum%E5%91%BD%E4%BB%A4%E8%A2%AB%E9%94%81%E8%A7%A3%E5%86%B3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/1/yum%E5%91%BD%E4%BB%A4%E8%A2%AB%E9%94%81%E8%A7%A3%E5%86%B3/</guid><description>root@centos001 ~]# yum clean all //执行一个yum命令 已加载插件：fastestmirror Repodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast /var/run/yum.pid 已被锁定，PID 为 2308 的另一个程序正在运行。 //可以看到文件被锁定 此处发现命令被锁，无法使用新的yum命令 解决方法
先用CTRL+Z暂停命令 输入命令： rm -f /var/run/yum.pid //删除这个文件 3 在执行yum命令就ok了
[root@centos001 ~]# yum clean all 已加载插件：fastestmirror 正在清理软件源： base extras updates Cleaning up everything</description></item></channel></rss>